{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Install pandas if not already installed\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    os.system('pip install pandas')\n",
    "\n",
    "# Set paths\n",
    "log_file_path = \"D:\\\\Data Engineering ETL project 1\\\\log_file.txt\"\n",
    "transformed_data_path = \"D:\\\\Data Engineering ETL project 1\\\\transformed_data.csv\"\n",
    "\n",
    "# Logging function\n",
    "def log(message):\n",
    "    with open(log_file_path, \"a\") as log_file:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        log_file.write(f\"[{timestamp}] {message}\\n\")\n",
    "\n",
    "# Extract Data\n",
    "\n",
    "def extract_csv(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def extract_json(file_path):\n",
    "    return pd.read_json(file_path,lines=True)\n",
    "\n",
    "def extract_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    data = []\n",
    "    columns = [elem.tag for elem in root[0]]\n",
    "    for row in root:\n",
    "        data.append([child.text for child in row])\n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "def extract_data(directory):\n",
    "    log(\"Starting data extraction\")\n",
    "    all_files = glob.glob(f\"{directory}/*\")\n",
    "    data_frames = []\n",
    "    for file in all_files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            data_frames.append(extract_csv(file))\n",
    "        elif file.endswith(\".json\"):\n",
    "            data_frames.append(extract_json(file))\n",
    "        elif file.endswith(\".xml\"):\n",
    "            data_frames.append(extract_xml(file))\n",
    "    combined_data = pd.concat(data_frames, ignore_index=True)\n",
    "    log(\"Data extraction completed\")\n",
    "    return combined_data\n",
    "\n",
    "# Transform Data\n",
    "def transform_data(df):\n",
    "    log(\"Starting data transformation\")\n",
    "    df['height'] = df['height'].astype(float) * 0.0254  # Inches to meters\n",
    "    df['weight'] = df['weight'].astype(float) * 0.453592  # Pounds to kilograms\n",
    "    log(\"Data transformation completed\")\n",
    "    return df\n",
    "\n",
    "# Load Data\n",
    "def load_data(df):\n",
    "    log(\"Starting data loading\")\n",
    "    df.to_csv(transformed_data_path, index=False)\n",
    "    log(\"Data loading completed\")\n",
    "\n",
    "# ETL Execution\n",
    "def run_etl(directory):\n",
    "    log(\"ETL process started\")\n",
    "\n",
    "    # Extraction\n",
    "    extracted_data = extract_data(directory)\n",
    "\n",
    "    # Transformation\n",
    "    transformed_data = transform_data(extracted_data)\n",
    "\n",
    "    # Loading\n",
    "    load_data(transformed_data)\n",
    "\n",
    "    log(\"ETL process completed\")\n",
    "\n",
    "# Example Usage\n",
    "# Set the directory containing your data files\n",
    "data_directory = \"C:\\\\Users\\\\Akshaya\\\\Downloads\\\\source\"\n",
    "run_etl(data_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
